2021-09-27 13:32:00 INFO Running runs: []
2021-09-27 13:32:00 INFO Agent received command: run
2021-09-27 13:32:00 INFO Agent starting run with config:
	components.entity_ruler.ent_id_sep: ||
	components.entity_ruler.factory: entity_ruler
	components.entity_ruler.overwrite_ents: true
	components.entity_ruler.validate: false
	components.ner.factory: ner
	components.ner.model.@architectures: spacy.TransitionBasedParser.v2
	components.ner.model.extra_state_tokens: true
	components.ner.model.hidden_width: 72
	components.ner.model.maxout_pieces: 1
	components.ner.model.state_type: ner
	components.ner.model.tok2vec.@architectures: spacy.Tok2Vec.v2
	components.ner.model.tok2vec.embed.@architectures: spacy.MultiHashEmbed.v2
	components.ner.model.tok2vec.embed.include_static_vectors: true
	components.ner.model.tok2vec.embed.width: 60
	components.ner.model.tok2vec.encode.@architectures: spacy.MaxoutWindowEncoder.v2
	components.ner.model.tok2vec.encode.depth: 3
	components.ner.model.tok2vec.encode.maxout_pieces: 6
	components.ner.model.tok2vec.encode.width: 127
	components.ner.model.tok2vec.encode.window_size: 1
	components.ner.model.tok2vec.upstream: *
	components.ner.model.tok2vec.width: 176
	components.ner.model.use_upper: false
	components.ner.update_with_oracle_cut_size: 103
	components.tok2vec.factory: tok2vec
	components.tok2vec.model.@architectures: spacy.Tok2Vec.v1
	components.tok2vec.model.embed.@architectures: spacy.MultiHashEmbed.v1
	components.tok2vec.model.embed.include_static_vectors: false
	components.tok2vec.model.embed.width: 86
	components.tok2vec.model.encode.@architectures: spacy.MaxoutWindowEncoder.v1
	components.tok2vec.model.encode.depth: 3
	components.tok2vec.model.encode.maxout_pieces: 2
	components.tok2vec.model.encode.width: 155
	components.tok2vec.model.encode.window_size: 2
	corpora.dev.@readers: spacy.Corpus.v1
	corpora.dev.gold_preproc: false
	corpora.dev.path: corpus/dev.spacy
	corpora.train.@readers: spacy.Corpus.v1
	corpora.train.gold_preproc: true
	corpora.train.max_length: 1181
	corpora.train.path: corpus/train.spacy
	initialize.components.entity_ruler.patterns.@readers: srsly.read_jsonl.v1
	initialize.components.entity_ruler.patterns.path: training/custom_model_md/entity_ruler/patterns.jsonl
	initialize.components.entity_ruler.patterns.skip: false
	initialize.lookups.@misc: spacy.LookupsDataLoader.v1
	initialize.lookups.lang: en
	initialize.vectors: training/custom_model_md
	nlp.batch_size: 535
	nlp.lang: en
	nlp.tokenizer.@tokenizers: spacy.Tokenizer.v1
	paths.dev: corpus/dev.spacy
	paths.train: corpus/train.spacy
	paths.vectors: training/custom_model_md
	training.accumulate_gradient: 1
	training.batcher.@batchers: spacy.batch_by_words.v1
	training.batcher.discard_oversize: false
	training.batcher.size.@schedules: compounding.v1
	training.batcher.size.compound: 1.4529029745174773
	training.batcher.size.start: 144
	training.batcher.size.stop: 1940
	training.batcher.tolerance: 0.15691985586182378
	training.dev_corpus: corpora.dev
	training.dropout: 0.09278847616839732
	training.eval_frequency: 269
	training.logger.@loggers: spacy.WandbLogger.v2
	training.logger.log_dataset_dir: ./corpus
	training.logger.model_log_interval: 507
	training.logger.project_name: NER-prodigy-logWandB
	training.max_steps: 37788
	training.optimizer.@optimizers: Adam.v1
	training.optimizer.beta1: 1.5531077083385572
	training.optimizer.beta2: 0.5018969628778508
	training.optimizer.eps: 9.519646416768129e-09
	training.optimizer.grad_clip: 1
	training.optimizer.l2: 0.014423691643776292
	training.optimizer.l2_is_weight_decay: true
	training.optimizer.learn_rate.@schedules: warmup_linear.v1
	training.optimizer.learn_rate.initial_rate: 8.051010532270488e-05
	training.optimizer.learn_rate.total_steps: 21128
	training.optimizer.learn_rate.warmup_steps: 377
	training.optimizer.use_averages: false
	training.patience: 1598
	training.score_weights.ents_f: 1
	training.train_corpus: corpora.train
	variables.wandb_project_name: NER-prodigy-logWandB
2021-09-27 13:32:00 INFO About to run command: python train.py --components.entity_ruler.ent_id_sep=|| --components.entity_ruler.factory=entity_ruler --components.entity_ruler.overwrite_ents=true --components.entity_ruler.validate=false --components.ner.factory=ner --components.ner.model.@architectures=spacy.TransitionBasedParser.v2 --components.ner.model.extra_state_tokens=true --components.ner.model.hidden_width=72 --components.ner.model.maxout_pieces=1 --components.ner.model.state_type=ner --components.ner.model.tok2vec.@architectures=spacy.Tok2Vec.v2 --components.ner.model.tok2vec.embed.@architectures=spacy.MultiHashEmbed.v2 --components.ner.model.tok2vec.embed.include_static_vectors=true --components.ner.model.tok2vec.embed.width=60 --components.ner.model.tok2vec.encode.@architectures=spacy.MaxoutWindowEncoder.v2 --components.ner.model.tok2vec.encode.depth=3 --components.ner.model.tok2vec.encode.maxout_pieces=6 --components.ner.model.tok2vec.encode.width=127 --components.ner.model.tok2vec.encode.window_size=1 --components.ner.model.tok2vec.upstream=* --components.ner.model.tok2vec.width=176 --components.ner.model.use_upper=false --components.ner.update_with_oracle_cut_size=103 --components.tok2vec.factory=tok2vec --components.tok2vec.model.@architectures=spacy.Tok2Vec.v1 --components.tok2vec.model.embed.@architectures=spacy.MultiHashEmbed.v1 --components.tok2vec.model.embed.include_static_vectors=false --components.tok2vec.model.embed.width=86 --components.tok2vec.model.encode.@architectures=spacy.MaxoutWindowEncoder.v1 --components.tok2vec.model.encode.depth=3 --components.tok2vec.model.encode.maxout_pieces=2 --components.tok2vec.model.encode.width=155 --components.tok2vec.model.encode.window_size=2 --corpora.dev.@readers=spacy.Corpus.v1 --corpora.dev.gold_preproc=false --corpora.dev.path=corpus/dev.spacy --corpora.train.@readers=spacy.Corpus.v1 --corpora.train.gold_preproc=true --corpora.train.max_length=1181 --corpora.train.path=corpus/train.spacy --initialize.components.entity_ruler.patterns.@readers=srsly.read_jsonl.v1 --initialize.components.entity_ruler.patterns.path=training/custom_model_md/entity_ruler/patterns.jsonl --initialize.components.entity_ruler.patterns.skip=false --initialize.lookups.@misc=spacy.LookupsDataLoader.v1 --initialize.lookups.lang=en --initialize.vectors=training/custom_model_md --nlp.batch_size=535 --nlp.lang=en --nlp.tokenizer.@tokenizers=spacy.Tokenizer.v1 --paths.dev=corpus/dev.spacy --paths.train=corpus/train.spacy --paths.vectors=training/custom_model_md --training.accumulate_gradient=1 --training.batcher.@batchers=spacy.batch_by_words.v1 --training.batcher.discard_oversize=false --training.batcher.size.@schedules=compounding.v1 --training.batcher.size.compound=1.4529029745174773 --training.batcher.size.start=144 --training.batcher.size.stop=1940 --training.batcher.tolerance=0.15691985586182378 --training.dev_corpus=corpora.dev --training.dropout=0.09278847616839732 --training.eval_frequency=269 --training.logger.@loggers=spacy.WandbLogger.v2 --training.logger.log_dataset_dir=./corpus --training.logger.model_log_interval=507 --training.logger.project_name=NER-prodigy-logWandB --training.max_steps=37788 --training.optimizer.@optimizers=Adam.v1 --training.optimizer.beta1=1.5531077083385572 --training.optimizer.beta2=0.5018969628778508 --training.optimizer.eps=9.519646416768129e-09 --training.optimizer.grad_clip=1 --training.optimizer.l2=0.014423691643776292 --training.optimizer.l2_is_weight_decay=true --training.optimizer.learn_rate.@schedules=warmup_linear.v1 --training.optimizer.learn_rate.initial_rate=8.051010532270488e-05 --training.optimizer.learn_rate.total_steps=21128 --training.optimizer.learn_rate.warmup_steps=377 --training.optimizer.use_averages=false --training.patience=1598 --training.score_weights.ents_f=1 --training.train_corpus=corpora.train --variables.wandb_project_name=NER-prodigy-logWandB
2021-09-27 13:32:05 INFO Running runs: ['488rp51y']
2021-09-27 13:32:05 INFO Cleaning up finished run: 488rp51y
2021-09-27 13:32:06 INFO Agent received command: run
2021-09-27 13:32:06 INFO Agent starting run with config:
	components.entity_ruler.ent_id_sep: ||
	components.entity_ruler.factory: entity_ruler
	components.entity_ruler.overwrite_ents: false
	components.entity_ruler.validate: false
	components.ner.factory: ner
	components.ner.model.@architectures: spacy.TransitionBasedParser.v2
	components.ner.model.extra_state_tokens: true
	components.ner.model.hidden_width: 53
	components.ner.model.maxout_pieces: 4
	components.ner.model.state_type: ner
	components.ner.model.tok2vec.@architectures: spacy.Tok2Vec.v2
	components.ner.model.tok2vec.embed.@architectures: spacy.MultiHashEmbed.v2
	components.ner.model.tok2vec.embed.include_static_vectors: true
	components.ner.model.tok2vec.embed.width: 150
	components.ner.model.tok2vec.encode.@architectures: spacy.MaxoutWindowEncoder.v2
	components.ner.model.tok2vec.encode.depth: 2
	components.ner.model.tok2vec.encode.maxout_pieces: 6
	components.ner.model.tok2vec.encode.width: 120
	components.ner.model.tok2vec.encode.window_size: 2
	components.ner.model.tok2vec.upstream: *
	components.ner.model.tok2vec.width: 139
	components.ner.model.use_upper: false
	components.ner.update_with_oracle_cut_size: 184
	components.tok2vec.factory: tok2vec
	components.tok2vec.model.@architectures: spacy.Tok2Vec.v1
	components.tok2vec.model.embed.@architectures: spacy.MultiHashEmbed.v1
	components.tok2vec.model.embed.include_static_vectors: false
	components.tok2vec.model.embed.width: 48
	components.tok2vec.model.encode.@architectures: spacy.MaxoutWindowEncoder.v1
	components.tok2vec.model.encode.depth: 6
	components.tok2vec.model.encode.maxout_pieces: 2
	components.tok2vec.model.encode.width: 110
	components.tok2vec.model.encode.window_size: 2
	corpora.dev.@readers: spacy.Corpus.v1
	corpora.dev.gold_preproc: true
	corpora.dev.path: corpus/dev.spacy
	corpora.train.@readers: spacy.Corpus.v1
	corpora.train.gold_preproc: false
	corpora.train.max_length: 1589
	corpora.train.path: corpus/train.spacy
	initialize.components.entity_ruler.patterns.@readers: srsly.read_jsonl.v1
	initialize.components.entity_ruler.patterns.path: training/custom_model_md/entity_ruler/patterns.jsonl
	initialize.components.entity_ruler.patterns.skip: true
	initialize.lookups.@misc: spacy.LookupsDataLoader.v1
	initialize.lookups.lang: en
	initialize.vectors: training/custom_model_md
	nlp.batch_size: 1785
	nlp.lang: en
	nlp.tokenizer.@tokenizers: spacy.Tokenizer.v1
	paths.dev: corpus/dev.spacy
	paths.train: corpus/train.spacy
	paths.vectors: training/custom_model_md
	training.accumulate_gradient: 2
	training.batcher.@batchers: spacy.batch_by_words.v1
	training.batcher.discard_oversize: true
	training.batcher.size.@schedules: compounding.v1
	training.batcher.size.compound: 1.1340365011536622
	training.batcher.size.start: 84
	training.batcher.size.stop: 1734
	training.batcher.tolerance: 0.15372968007664045
	training.dev_corpus: corpora.dev
	training.dropout: 0.13860618292597682
	training.eval_frequency: 255
	training.logger.@loggers: spacy.WandbLogger.v2
	training.logger.log_dataset_dir: ./corpus
	training.logger.model_log_interval: 1304
	training.logger.project_name: NER-prodigy-logWandB
	training.max_steps: 14272
	training.optimizer.@optimizers: Adam.v1
	training.optimizer.beta1: 1.7923298447391385
	training.optimizer.beta2: 1.2727408318190156
	training.optimizer.eps: 1.51087346096269e-08
	training.optimizer.grad_clip: 1
	training.optimizer.l2: 0.013924304829014082
	training.optimizer.l2_is_weight_decay: false
	training.optimizer.learn_rate.@schedules: warmup_linear.v1
	training.optimizer.learn_rate.initial_rate: 6.391775114164132e-05
	training.optimizer.learn_rate.total_steps: 13972
	training.optimizer.learn_rate.warmup_steps: 407
	training.optimizer.use_averages: false
	training.patience: 2423
	training.score_weights.ents_f: 2
	training.train_corpus: corpora.train
	variables.wandb_project_name: NER-prodigy-logWandB
2021-09-27 13:32:06 INFO About to run command: python train.py --components.entity_ruler.ent_id_sep=|| --components.entity_ruler.factory=entity_ruler --components.entity_ruler.overwrite_ents=false --components.entity_ruler.validate=false --components.ner.factory=ner --components.ner.model.@architectures=spacy.TransitionBasedParser.v2 --components.ner.model.extra_state_tokens=true --components.ner.model.hidden_width=53 --components.ner.model.maxout_pieces=4 --components.ner.model.state_type=ner --components.ner.model.tok2vec.@architectures=spacy.Tok2Vec.v2 --components.ner.model.tok2vec.embed.@architectures=spacy.MultiHashEmbed.v2 --components.ner.model.tok2vec.embed.include_static_vectors=true --components.ner.model.tok2vec.embed.width=150 --components.ner.model.tok2vec.encode.@architectures=spacy.MaxoutWindowEncoder.v2 --components.ner.model.tok2vec.encode.depth=2 --components.ner.model.tok2vec.encode.maxout_pieces=6 --components.ner.model.tok2vec.encode.width=120 --components.ner.model.tok2vec.encode.window_size=2 --components.ner.model.tok2vec.upstream=* --components.ner.model.tok2vec.width=139 --components.ner.model.use_upper=false --components.ner.update_with_oracle_cut_size=184 --components.tok2vec.factory=tok2vec --components.tok2vec.model.@architectures=spacy.Tok2Vec.v1 --components.tok2vec.model.embed.@architectures=spacy.MultiHashEmbed.v1 --components.tok2vec.model.embed.include_static_vectors=false --components.tok2vec.model.embed.width=48 --components.tok2vec.model.encode.@architectures=spacy.MaxoutWindowEncoder.v1 --components.tok2vec.model.encode.depth=6 --components.tok2vec.model.encode.maxout_pieces=2 --components.tok2vec.model.encode.width=110 --components.tok2vec.model.encode.window_size=2 --corpora.dev.@readers=spacy.Corpus.v1 --corpora.dev.gold_preproc=true --corpora.dev.path=corpus/dev.spacy --corpora.train.@readers=spacy.Corpus.v1 --corpora.train.gold_preproc=false --corpora.train.max_length=1589 --corpora.train.path=corpus/train.spacy --initialize.components.entity_ruler.patterns.@readers=srsly.read_jsonl.v1 --initialize.components.entity_ruler.patterns.path=training/custom_model_md/entity_ruler/patterns.jsonl --initialize.components.entity_ruler.patterns.skip=true --initialize.lookups.@misc=spacy.LookupsDataLoader.v1 --initialize.lookups.lang=en --initialize.vectors=training/custom_model_md --nlp.batch_size=1785 --nlp.lang=en --nlp.tokenizer.@tokenizers=spacy.Tokenizer.v1 --paths.dev=corpus/dev.spacy --paths.train=corpus/train.spacy --paths.vectors=training/custom_model_md --training.accumulate_gradient=2 --training.batcher.@batchers=spacy.batch_by_words.v1 --training.batcher.discard_oversize=true --training.batcher.size.@schedules=compounding.v1 --training.batcher.size.compound=1.1340365011536622 --training.batcher.size.start=84 --training.batcher.size.stop=1734 --training.batcher.tolerance=0.15372968007664045 --training.dev_corpus=corpora.dev --training.dropout=0.13860618292597682 --training.eval_frequency=255 --training.logger.@loggers=spacy.WandbLogger.v2 --training.logger.log_dataset_dir=./corpus --training.logger.model_log_interval=1304 --training.logger.project_name=NER-prodigy-logWandB --training.max_steps=14272 --training.optimizer.@optimizers=Adam.v1 --training.optimizer.beta1=1.7923298447391385 --training.optimizer.beta2=1.2727408318190156 --training.optimizer.eps=1.51087346096269e-08 --training.optimizer.grad_clip=1 --training.optimizer.l2=0.013924304829014082 --training.optimizer.l2_is_weight_decay=false --training.optimizer.learn_rate.@schedules=warmup_linear.v1 --training.optimizer.learn_rate.initial_rate=6.391775114164132e-05 --training.optimizer.learn_rate.total_steps=13972 --training.optimizer.learn_rate.warmup_steps=407 --training.optimizer.use_averages=false --training.patience=2423 --training.score_weights.ents_f=2 --training.train_corpus=corpora.train --variables.wandb_project_name=NER-prodigy-logWandB
2021-09-27 13:32:11 INFO Running runs: ['6sdvmg8i']
2021-09-27 13:32:11 INFO Cleaning up finished run: 6sdvmg8i
2021-09-27 13:32:11 INFO Agent received command: run
2021-09-27 13:32:11 INFO Agent starting run with config:
	components.entity_ruler.ent_id_sep: ||
	components.entity_ruler.factory: entity_ruler
	components.entity_ruler.overwrite_ents: false
	components.entity_ruler.validate: true
	components.ner.factory: ner
	components.ner.model.@architectures: spacy.TransitionBasedParser.v2
	components.ner.model.extra_state_tokens: false
	components.ner.model.hidden_width: 80
	components.ner.model.maxout_pieces: 2
	components.ner.model.state_type: ner
	components.ner.model.tok2vec.@architectures: spacy.Tok2Vec.v2
	components.ner.model.tok2vec.embed.@architectures: spacy.MultiHashEmbed.v2
	components.ner.model.tok2vec.embed.include_static_vectors: false
	components.ner.model.tok2vec.embed.width: 166
	components.ner.model.tok2vec.encode.@architectures: spacy.MaxoutWindowEncoder.v2
	components.ner.model.tok2vec.encode.depth: 6
	components.ner.model.tok2vec.encode.maxout_pieces: 2
	components.ner.model.tok2vec.encode.width: 52
	components.ner.model.tok2vec.encode.window_size: 1
	components.ner.model.tok2vec.upstream: *
	components.ner.model.tok2vec.width: 192
	components.ner.model.use_upper: false
	components.ner.update_with_oracle_cut_size: 106
	components.tok2vec.factory: tok2vec
	components.tok2vec.model.@architectures: spacy.Tok2Vec.v1
	components.tok2vec.model.embed.@architectures: spacy.MultiHashEmbed.v1
	components.tok2vec.model.embed.include_static_vectors: false
	components.tok2vec.model.embed.width: 159
	components.tok2vec.model.encode.@architectures: spacy.MaxoutWindowEncoder.v1
	components.tok2vec.model.encode.depth: 4
	components.tok2vec.model.encode.maxout_pieces: 5
	components.tok2vec.model.encode.width: 159
	components.tok2vec.model.encode.window_size: 2
	corpora.dev.@readers: spacy.Corpus.v1
	corpora.dev.gold_preproc: true
	corpora.dev.path: corpus/dev.spacy
	corpora.train.@readers: spacy.Corpus.v1
	corpora.train.gold_preproc: false
	corpora.train.max_length: 3055
	corpora.train.path: corpus/train.spacy
	initialize.components.entity_ruler.patterns.@readers: srsly.read_jsonl.v1
	initialize.components.entity_ruler.patterns.path: training/custom_model_md/entity_ruler/patterns.jsonl
	initialize.components.entity_ruler.patterns.skip: true
	initialize.lookups.@misc: spacy.LookupsDataLoader.v1
	initialize.lookups.lang: en
	initialize.vectors: training/custom_model_md
	nlp.batch_size: 1004
	nlp.lang: en
	nlp.tokenizer.@tokenizers: spacy.Tokenizer.v1
	paths.dev: corpus/dev.spacy
	paths.train: corpus/train.spacy
	paths.vectors: training/custom_model_md
	training.accumulate_gradient: 1
	training.batcher.@batchers: spacy.batch_by_words.v1
	training.batcher.discard_oversize: true
	training.batcher.size.@schedules: compounding.v1
	training.batcher.size.compound: 1.2085893840843576
	training.batcher.size.start: 60
	training.batcher.size.stop: 1685
	training.batcher.tolerance: 0.18458248816482875
	training.dev_corpus: corpora.dev
	training.dropout: 0.1490387362556091
	training.eval_frequency: 185
	training.logger.@loggers: spacy.WandbLogger.v2
	training.logger.log_dataset_dir: ./corpus
	training.logger.model_log_interval: 1015
	training.logger.project_name: NER-prodigy-logWandB
	training.max_steps: 25091
	training.optimizer.@optimizers: Adam.v1
	training.optimizer.beta1: 0.5529299884777417
	training.optimizer.beta2: 0.8345530163397397
	training.optimizer.eps: 1.6067885117803736e-08
	training.optimizer.grad_clip: 1
	training.optimizer.l2: 0.010013701647246432
	training.optimizer.l2_is_weight_decay: true
	training.optimizer.learn_rate.@schedules: warmup_linear.v1
	training.optimizer.learn_rate.initial_rate: 9.435391380157194e-05
	training.optimizer.learn_rate.total_steps: 17004
	training.optimizer.learn_rate.warmup_steps: 332
	training.optimizer.use_averages: false
	training.patience: 3153
	training.score_weights.ents_f: 2
	training.train_corpus: corpora.train
	variables.wandb_project_name: NER-prodigy-logWandB
2021-09-27 13:32:11 INFO About to run command: python train.py --components.entity_ruler.ent_id_sep=|| --components.entity_ruler.factory=entity_ruler --components.entity_ruler.overwrite_ents=false --components.entity_ruler.validate=true --components.ner.factory=ner --components.ner.model.@architectures=spacy.TransitionBasedParser.v2 --components.ner.model.extra_state_tokens=false --components.ner.model.hidden_width=80 --components.ner.model.maxout_pieces=2 --components.ner.model.state_type=ner --components.ner.model.tok2vec.@architectures=spacy.Tok2Vec.v2 --components.ner.model.tok2vec.embed.@architectures=spacy.MultiHashEmbed.v2 --components.ner.model.tok2vec.embed.include_static_vectors=false --components.ner.model.tok2vec.embed.width=166 --components.ner.model.tok2vec.encode.@architectures=spacy.MaxoutWindowEncoder.v2 --components.ner.model.tok2vec.encode.depth=6 --components.ner.model.tok2vec.encode.maxout_pieces=2 --components.ner.model.tok2vec.encode.width=52 --components.ner.model.tok2vec.encode.window_size=1 --components.ner.model.tok2vec.upstream=* --components.ner.model.tok2vec.width=192 --components.ner.model.use_upper=false --components.ner.update_with_oracle_cut_size=106 --components.tok2vec.factory=tok2vec --components.tok2vec.model.@architectures=spacy.Tok2Vec.v1 --components.tok2vec.model.embed.@architectures=spacy.MultiHashEmbed.v1 --components.tok2vec.model.embed.include_static_vectors=false --components.tok2vec.model.embed.width=159 --components.tok2vec.model.encode.@architectures=spacy.MaxoutWindowEncoder.v1 --components.tok2vec.model.encode.depth=4 --components.tok2vec.model.encode.maxout_pieces=5 --components.tok2vec.model.encode.width=159 --components.tok2vec.model.encode.window_size=2 --corpora.dev.@readers=spacy.Corpus.v1 --corpora.dev.gold_preproc=true --corpora.dev.path=corpus/dev.spacy --corpora.train.@readers=spacy.Corpus.v1 --corpora.train.gold_preproc=false --corpora.train.max_length=3055 --corpora.train.path=corpus/train.spacy --initialize.components.entity_ruler.patterns.@readers=srsly.read_jsonl.v1 --initialize.components.entity_ruler.patterns.path=training/custom_model_md/entity_ruler/patterns.jsonl --initialize.components.entity_ruler.patterns.skip=true --initialize.lookups.@misc=spacy.LookupsDataLoader.v1 --initialize.lookups.lang=en --initialize.vectors=training/custom_model_md --nlp.batch_size=1004 --nlp.lang=en --nlp.tokenizer.@tokenizers=spacy.Tokenizer.v1 --paths.dev=corpus/dev.spacy --paths.train=corpus/train.spacy --paths.vectors=training/custom_model_md --training.accumulate_gradient=1 --training.batcher.@batchers=spacy.batch_by_words.v1 --training.batcher.discard_oversize=true --training.batcher.size.@schedules=compounding.v1 --training.batcher.size.compound=1.2085893840843576 --training.batcher.size.start=60 --training.batcher.size.stop=1685 --training.batcher.tolerance=0.18458248816482875 --training.dev_corpus=corpora.dev --training.dropout=0.1490387362556091 --training.eval_frequency=185 --training.logger.@loggers=spacy.WandbLogger.v2 --training.logger.log_dataset_dir=./corpus --training.logger.model_log_interval=1015 --training.logger.project_name=NER-prodigy-logWandB --training.max_steps=25091 --training.optimizer.@optimizers=Adam.v1 --training.optimizer.beta1=0.5529299884777417 --training.optimizer.beta2=0.8345530163397397 --training.optimizer.eps=1.6067885117803736e-08 --training.optimizer.grad_clip=1 --training.optimizer.l2=0.010013701647246432 --training.optimizer.l2_is_weight_decay=true --training.optimizer.learn_rate.@schedules=warmup_linear.v1 --training.optimizer.learn_rate.initial_rate=9.435391380157194e-05 --training.optimizer.learn_rate.total_steps=17004 --training.optimizer.learn_rate.warmup_steps=332 --training.optimizer.use_averages=false --training.patience=3153 --training.score_weights.ents_f=2 --training.train_corpus=corpora.train --variables.wandb_project_name=NER-prodigy-logWandB

2021-09-17 13:39:25,510 INFO    MainThread:16436 [wandb_setup.py:_flush():69] setting env: {}
2021-09-17 13:39:25,510 INFO    MainThread:16436 [wandb_setup.py:_flush():69] setting login settings: {}
2021-09-17 13:39:25,510 INFO    MainThread:16436 [wandb_init.py:_log_setup():342] Logging user logs to C:\Users\astelzl\Documents\02_DEV\01_Code_Thesis\NER-prodigy-logWandB\wandb\run-20210917_133925-2etscltx\logs\debug.log
2021-09-17 13:39:25,510 INFO    MainThread:16436 [wandb_init.py:_log_setup():343] Logging internal logs to C:\Users\astelzl\Documents\02_DEV\01_Code_Thesis\NER-prodigy-logWandB\wandb\run-20210917_133925-2etscltx\logs\debug-internal.log
2021-09-17 13:39:25,510 INFO    MainThread:16436 [wandb_init.py:init():375] calling init triggers
2021-09-17 13:39:25,511 INFO    MainThread:16436 [wandb_init.py:init():380] wandb.init called with sweep_config: {}
config: {'components': {'ner': {'factory': 'ner', 'incorrect_spans_key': None, 'moves': None, 'update_with_oracle_cut_size': 100, 'model': {'@architectures': 'spacy.TransitionBasedParser.v2', 'state_type': 'ner', 'extra_state_tokens': False, 'hidden_width': 64, 'maxout_pieces': 2, 'use_upper': True, 'no': None, 'tok2vec': {'@architectures': 'spacy.Tok2VecListener.v1', 'width': 96, 'upstream': '*'}}}, 'tok2vec': {'factory': 'tok2vec', 'model': {'@architectures': 'spacy.Tok2Vec.v1', 'embed': {'@architectures': 'spacy.MultiHashEmbed.v1', 'width': 96, 'rows': [2000, 1000, 1000, 1000], 'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE'], 'include_static_vectors': False}, 'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v1', 'width': 96, 'depth': 4, 'window_size': 1, 'maxout_pieces': 3}}}}, 'corpora': {'dev': {'@readers': 'spacy.Corpus.v1', 'path': 'corpus/dev.spacy', 'max_length': 0, 'gold_preproc': False, 'limit': 0, 'augmenter': None}, 'train': {'@readers': 'spacy.Corpus.v1', 'path': 'corpus/train.spacy', 'max_length': 2000, 'gold_preproc': False, 'limit': 0, 'augmenter': None}}, 'initialize': {'vectors': 'training/custom_model_md', 'init_tok2vec': None, 'vocab_data': None, 'lookups': None, 'before_init': None, 'after_init': None}, 'nlp': {'lang': 'en', 'pipeline': ['tok2vec', 'ner'], 'tokenizer': {'@tokenizers': 'spacy.Tokenizer.v1'}, 'before_creation': None, 'after_creation': None, 'after_pipeline_creation': None, 'disabled': [], 'batch_size': 1000}, 'paths': {'train': 'corpus/train.spacy', 'dev': 'corpus/dev.spacy', 'raw': None, 'init_tok2vec': None, 'vectors': 'training/custom_model_md'}, 'system': {'gpu_allocator': None, 'seed': 0}, 'training': {'train_corpus': 'corpora.train', 'dev_corpus': 'corpora.dev', 'seed': 0, 'gpu_allocator': None, 'dropout': 0.1, 'accumulate_gradient': 1, 'patience': 1600, 'max_epochs': 0, 'max_steps': 20000, 'eval_frequency': 200, 'frozen_components': [], 'before_to_disk': None, 'annotating_components': [], 'batcher': {'@batchers': 'spacy.batch_by_words.v1', 'discard_oversize': False, 'tolerance': 0.2, 'get_length': None, 'size': {'@schedules': 'compounding.v1', 'start': 100, 'stop': 1000, 'compound': 1.001, 't': 0.0}}, 'logger': {'@loggers': 'spacy.WandbLogger.v2', 'project_name': 'NER-prodigy-logWandB', 'remove_config_values': [], 'model_log_interval': None, 'log_dataset_dir': None}, 'optimizer': {'@optimizers': 'Adam.v1', 'beta1': 0.9, 'beta2': 0.999, 'l2_is_weight_decay': True, 'l2': 0.01, 'grad_clip': 1.0, 'use_averages': False, 'eps': 1e-08, 'learn_rate': {'@schedules': 'warmup_linear.v1', 'warmup_steps': 250, 'total_steps': 20000, 'initial_rate': 5e-05}}, 'score_weights': {'ents_f': 1.0, 'ents_p': 0.0, 'ents_r': 0.0, 'ents_per_type': None}}, 'variables': {'wandb_project_name': 'NER-prodigy-logWandB'}}
2021-09-17 13:39:25,511 INFO    MainThread:16436 [wandb_init.py:init():424] starting backend
2021-09-17 13:39:25,511 INFO    MainThread:16436 [backend.py:_multiprocessing_setup():70] multiprocessing start_methods=spawn, using: spawn
2021-09-17 13:39:25,515 INFO    MainThread:16436 [backend.py:ensure_launched():135] starting backend process...
2021-09-17 13:39:25,591 INFO    MainThread:16436 [backend.py:ensure_launched():139] started backend process with pid: 23764
2021-09-17 13:39:25,591 INFO    MainThread:16436 [wandb_init.py:init():429] backend started and connected
2021-09-17 13:39:25,593 INFO    MainThread:16436 [wandb_init.py:init():477] updated telemetry
2021-09-17 13:39:25,593 INFO    MainThread:16436 [wandb_init.py:init():500] communicating current version
2021-09-17 13:39:26,386 INFO    MainThread:16436 [wandb_init.py:init():505] got version response upgrade_message: "wandb version 0.12.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2021-09-17 13:39:26,388 INFO    MainThread:16436 [wandb_init.py:init():513] communicating run to backend with 30 second timeout
2021-09-17 13:39:26,690 INFO    MainThread:16436 [wandb_init.py:init():540] starting run threads in backend
2021-09-17 13:39:27,508 INFO    MainThread:16436 [wandb_run.py:_console_start():1601] atexit reg
2021-09-17 13:39:27,509 INFO    MainThread:16436 [wandb_run.py:_redirect():1475] redirect: SettingsConsole.WRAP
2021-09-17 13:39:27,509 INFO    MainThread:16436 [wandb_run.py:_redirect():1512] Wrapping output streams.
2021-09-17 13:39:27,511 INFO    MainThread:16436 [wandb_run.py:_redirect():1536] Redirects installed.
2021-09-17 13:39:27,511 INFO    MainThread:16436 [wandb_init.py:init():565] run started, returning control to user process
2021-09-17 13:46:46,838 INFO    MainThread:16436 [wandb_run.py:finish():1271] finishing run alfred-ls/NER-prodigy-logWandB/2etscltx
